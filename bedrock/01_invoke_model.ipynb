{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9182f200-3e1d-480e-b588-d05aa36904f0",
   "metadata": {},
   "source": [
    "# Referências da Documentação AWS:\n",
    "\n",
    "- https://docs.aws.amazon.com/bedrock/latest/userguide/inference-invoke.html\n",
    "\n",
    "- https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_InvokeModelWithResponseStream.html\n",
    "\n",
    "- hytps://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-runtime/client/invoke_model.html\n",
    "\n",
    "# Dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b393a8b-d717-4ecc-aab2-2efd96326918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4db116e-09a3-4f85-bb9e-09c8d4747fc0",
   "metadata": {},
   "source": [
    "# Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a591590b-9007-47a3-b7a1-bce2b8dd8015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasta local para salvar respostas das chamadas AWS\n",
    "OUTPUT_FOLDER = \"respostas\"\n",
    "\n",
    "# ID do modelo Amazon Nova Lite (modelo de linguagem da AWS)\n",
    "MODEL_ID = 'amazon.nova-lite-v1:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05077c41-e3c4-4bb3-9dfa-d4391b701d17",
   "metadata": {},
   "source": [
    "# Criar pasta local para respostas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fed6f0d-957b-4a03-8e56-5efdeaab6a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca96b09-be9b-4ac9-bed9-982e4b5d1b87",
   "metadata": {},
   "source": [
    "# Configurações do AWS BEDROCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38071e2d-61e8-4fd2-b464-bce82ef3c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o cliente do Bedrock Runtime para fazer chamadas à API\n",
    "bedrock_runtime_client = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dc461e-4528-4d51-aa42-64aead63e7e7",
   "metadata": {},
   "source": [
    "# Configuração da requisição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd38865-b4cb-4232-87ed-bcccf4f1fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pergunta que será enviada ao modelo\n",
    "prompt = \"Resuma a história do Brasil em 4 parágrafos.\"\n",
    "\n",
    "# Estrutura da requisição seguindo o formato messages-v1 do Bedrock\n",
    "body = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",           # Papel do remetente da mensagem\n",
    "            \"content\": [{\"text\": prompt}]  # Conteúdo da mensagem\n",
    "        }\n",
    "    ],\n",
    "    \"inferenceConfig\": {\n",
    "        \"maxTokens\": 400,    # Máximo de tokens na resposta (controla o tamanho)\n",
    "        \"temperature\": 0.7   # Criatividade da resposta (0.0 = conservador, 1.0 = criativo)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cee3280-19ea-4176-b072-1dc6ca0d3aa2",
   "metadata": {},
   "source": [
    "# Teste 1: invoke_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc13084-335c-4b62-89a8-f5fd1a8c6282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este método retorna a resposta completa de uma só vez (não streaming)\n",
    "response = bedrock_runtime_client.invoke_model(\n",
    "    body=json.dumps(body),              # Converte o corpo para JSON\n",
    "    contentType='application/json',      # Tipo de conteúdo da requisição\n",
    "    accept='application/json',           # Tipo de resposta aceito\n",
    "    modelId=MODEL_ID                    # ID do modelo a ser usado\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae93cd1-3955-4f83-99cb-665e5becb310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva a resposta completa (metadados + conteúdo) em arquivo JSON\n",
    "with open(f'{OUTPUT_FOLDER}/invoke_model_01.json', 'w') as file:\n",
    "    json.dump(response, file, indent=4, default=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a2a262-1c9a-46de-9b43-3eeb212ee0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrai e salva apenas o corpo da resposta (sem metadados)\n",
    "response_body = json.loads(response['body'].read())\n",
    "with open(f'{OUTPUT_FOLDER}/invoke_model_02.json', 'w') as file:\n",
    "    json.dump(response_body, file, indent=4, default=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3671ee-1d99-45fb-aaa2-155e3ca5dd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrai o texto da resposta do modelo e exibe\n",
    "texto_completo = response_body['output']['message']['content'][0]['text']\n",
    "print(f\"\\nResposta do modelo:\\n{texto_completo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579c1e55-7d53-4857-a104-a5c2b693eead",
   "metadata": {},
   "source": [
    "# Test 2: invoke_model_with_response_stream (Streaming) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bdd77b-1e74-4f29-9383-fc4f73eb72b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_stream = bedrock_runtime_client.invoke_model_with_response_stream(\n",
    "    body=json.dumps(body),              # Mesmo corpo da requisição anterior\n",
    "    contentType='application/json',\n",
    "    accept='application/json',\n",
    "    modelId=MODEL_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f8fdb1-dda4-4fcd-a239-c7b7042b62e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva a resposta completa (metadados + conteúdo) em arquivo JSON\n",
    "with open(f'{OUTPUT_FOLDER}/invoke_model_03.json', 'w') as file:\n",
    "    json.dump(response_stream, file, indent=4, default=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dba654-1441-4b92-81cd-58928dcfa99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este método retorna a resposta em pedaços (chunks) conforme é gerada\n",
    "response_stream = bedrock_runtime_client.invoke_model_with_response_stream(\n",
    "    body=json.dumps(body),              # Mesmo corpo da requisição anterior\n",
    "    contentType='application/json',\n",
    "    accept='application/json',\n",
    "    modelId=MODEL_ID\n",
    ")\n",
    "print(\"\\nResposta em tempo real: \", end=\"\", flush=True)\n",
    "\n",
    "# Variável para acumular o texto completo da resposta streaming\n",
    "texto_stream = \"\"\n",
    "\n",
    "# Processa cada evento do stream de resposta\n",
    "for event in response_stream['body']:\n",
    "    # Decodifica o chunk JSON recebido\n",
    "    chunk = json.loads(event['chunk']['bytes'])    \n",
    "    \n",
    "    # Verifica se o chunk contém texto da resposta\n",
    "    if 'contentBlockDelta' in chunk:\n",
    "        # Extrai o texto parcial deste chunk\n",
    "        delta_text = chunk['contentBlockDelta']['delta']['text']\n",
    "        # Exibe o texto imediatamente (efeito de digitação em tempo real)\n",
    "        print(delta_text, end=\"\", flush=True)\n",
    "        # Acumula o texto para ter a resposta completa no final\n",
    "        texto_stream += delta_text\n",
    "    \n",
    "    # Gera timestamp único para cada chunk (para debug/análise)\n",
    "    timestamp_parcial = datetime.now(timezone.utc).strftime('%Y%m%d%H%M%S%f')\n",
    "    \n",
    "    # Salva cada evento individual para análise posterior\n",
    "    filename_parcial = os.path.join(OUTPUT_FOLDER, f\"partial_{timestamp_parcial}.json\")\n",
    "    with open(filename_parcial, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(event, json_file, ensure_ascii=False, indent=4, default=str)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17ec75f-4acf-4018-ac77-31abc6cfcfd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Treinamento AWS GenAI",
   "language": "python",
   "name": "treinamento-aws-genai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
